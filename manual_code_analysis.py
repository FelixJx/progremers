#!/usr/bin/env python3.11
"""
æ‰‹åŠ¨ä»£ç åˆ†æå·¥å…· - æ¨¡æ‹ŸSerena MCPçš„ç¬¦å·çº§åˆ†æåŠŸèƒ½
åˆ†æé…’åº—åˆ†æå·¥å…·é¡¹ç›®çš„ä»£ç ç»“æ„å’Œè´¨é‡
"""

import os
import ast
import json
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict

def analyze_project_structure(project_path: str) -> Dict[str, Any]:
    """åˆ†æé¡¹ç›®ç»“æ„"""
    
    analysis = {
        "project_overview": {},
        "code_metrics": {},
        "dependency_analysis": {},
        "architecture_patterns": {},
        "code_quality_issues": [],
        "improvement_suggestions": []
    }
    
    project_path = Path(project_path)
    
    # åŸºç¡€ç»Ÿè®¡
    total_files = 0
    python_files = 0
    lines_of_code = 0
    
    # ä»£ç ç»“æ„åˆ†æ
    classes = []
    functions = []
    imports = defaultdict(int)
    
    for py_file in project_path.rglob("*.py"):
        if "venv" in str(py_file) or "__pycache__" in str(py_file):
            continue
            
        python_files += 1
        
        try:
            with open(py_file, 'r', encoding='utf-8') as f:
                content = f.read()
                lines_of_code += len(content.split('\n'))
                
            # ASTè§£æ
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    classes.append({
                        "name": node.name,
                        "file": str(py_file.relative_to(project_path)),
                        "line": node.lineno,
                        "methods": [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                    })
                elif isinstance(node, ast.FunctionDef):
                    functions.append({
                        "name": node.name,
                        "file": str(py_file.relative_to(project_path)),
                        "line": node.lineno,
                        "args": len(node.args.args)
                    })
                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        imports[alias.name] += 1
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports[node.module] += 1
                        
        except Exception as e:
            analysis["code_quality_issues"].append(f"è§£æé”™è¯¯ {py_file}: {str(e)}")
    
    # ç»Ÿè®¡åˆ†æ
    analysis["project_overview"] = {
        "total_python_files": python_files,
        "total_lines_of_code": lines_of_code,
        "average_file_size": lines_of_code // python_files if python_files > 0 else 0,
        "total_classes": len(classes),
        "total_functions": len(functions)
    }
    
    # æ ¸å¿ƒä¸šåŠ¡ç±»åˆ†æ
    core_classes = [cls for cls in classes if any(
        keyword in cls["name"].lower() 
        for keyword in ["analyzer", "calculator", "monitor", "service", "manager"]
    )]
    
    analysis["architecture_patterns"] = {
        "core_business_classes": len(core_classes),
        "service_classes": len([cls for cls in classes if "service" in cls["name"].lower()]),
        "analyzer_classes": len([cls for cls in classes if "analyzer" in cls["name"].lower()]),
        "model_classes": len([cls for cls in classes if any(
            "model" in cls["file"] for cls in classes
        )])
    }
    
    # ä¾èµ–åˆ†æ
    top_imports = dict(sorted(imports.items(), key=lambda x: x[1], reverse=True)[:10])
    analysis["dependency_analysis"] = {
        "total_unique_imports": len(imports),
        "most_used_imports": top_imports,
        "external_dependencies": {
            "data_processing": imports.get("pandas", 0) + imports.get("numpy", 0),
            "web_framework": imports.get("fastapi", 0) + imports.get("starlette", 0),
            "database": imports.get("sqlalchemy", 0) + imports.get("pymysql", 0),
            "async_processing": imports.get("asyncio", 0) + imports.get("aiohttp", 0)
        }
    }
    
    # ä»£ç è´¨é‡è¯„ä¼°
    analysis["code_metrics"] = {
        "complexity_indicators": {
            "large_classes": len([cls for cls in classes if len(cls["methods"]) > 10]),
            "long_functions": len([func for func in functions if func["args"] > 5]),
            "deep_file_structure": len([cls for cls in classes if cls["file"].count("/") > 3])
        },
        "maintainability_score": calculate_maintainability_score(classes, functions, lines_of_code)
    }
    
    # æ”¹è¿›å»ºè®®
    analysis["improvement_suggestions"] = generate_improvement_suggestions(analysis)
    
    return analysis

def calculate_maintainability_score(classes: List, functions: List, total_loc: int) -> float:
    """è®¡ç®—å¯ç»´æŠ¤æ€§è¯„åˆ† (0-10)"""
    
    score = 10.0
    
    # ç±»å¤æ‚åº¦æƒ©ç½š
    large_classes = len([cls for cls in classes if len(cls["methods"]) > 10])
    score -= (large_classes * 0.5)
    
    # å‡½æ•°å¤æ‚åº¦æƒ©ç½š  
    complex_functions = len([func for func in functions if func["args"] > 5])
    score -= (complex_functions * 0.3)
    
    # ä»£ç è¡Œæ•°æƒ©ç½š
    if total_loc > 10000:
        score -= 1.0
    elif total_loc > 5000:
        score -= 0.5
    
    return max(0.0, min(10.0, score))

def generate_improvement_suggestions(analysis: Dict) -> List[str]:
    """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
    
    suggestions = []
    
    metrics = analysis["code_metrics"]["complexity_indicators"]
    
    if metrics["large_classes"] > 3:
        suggestions.append("ğŸ”§ å‘ç°å¤šä¸ªå¤§å‹ç±»ï¼Œå»ºè®®æ‹†åˆ†ä¸ºæ›´å°çš„å•ä¸€èŒè´£ç±»")
    
    if metrics["long_functions"] > 5:
        suggestions.append("ğŸ”§ å‘ç°å¤šä¸ªå¤æ‚å‡½æ•°ï¼Œå»ºè®®é‡æ„ä¸ºæ›´å°çš„å‡½æ•°")
    
    if analysis["project_overview"]["average_file_size"] > 500:
        suggestions.append("ğŸ”§ å¹³å‡æ–‡ä»¶å¤§å°è¾ƒå¤§ï¼Œå»ºè®®æ‹†åˆ†æ¨¡å—")
    
    # æ¶æ„å»ºè®®
    arch = analysis["architecture_patterns"]
    if arch["service_classes"] < 3:
        suggestions.append("ğŸ—ï¸ å»ºè®®å¢åŠ æ›´å¤šæœåŠ¡å±‚ç±»ï¼Œæå‡ä»£ç åˆ†å±‚")
    
    if arch["analyzer_classes"] > arch["service_classes"]:
        suggestions.append("ğŸ—ï¸ åˆ†æå™¨ç±»è¿‡å¤šï¼Œå»ºè®®æ•´åˆåˆ°ç»Ÿä¸€çš„åˆ†ææœåŠ¡ä¸­")
    
    # ä¾èµ–å»ºè®®
    deps = analysis["dependency_analysis"]["external_dependencies"]
    if deps["async_processing"] < 5:
        suggestions.append("âš¡ å¼‚æ­¥å¤„ç†ä½¿ç”¨è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ å¼‚æ­¥æ“ä½œæå‡æ€§èƒ½")
    
    if deps["database"] > 10:
        suggestions.append("ğŸ—„ï¸ æ•°æ®åº“æ“ä½œè¾ƒå¤šï¼Œå»ºè®®æ·»åŠ è¿æ¥æ± å’Œç¼“å­˜ä¼˜åŒ–")
    
    return suggestions

def analyze_business_logic_patterns(project_path: str) -> Dict[str, Any]:
    """åˆ†æä¸šåŠ¡é€»è¾‘æ¨¡å¼"""
    
    project_path = Path(project_path)
    
    patterns = {
        "roi_calculation_patterns": [],
        "data_collection_patterns": [], 
        "analysis_patterns": [],
        "api_patterns": []
    }
    
    # åˆ†æROIè®¡ç®—æ¨¡å¼
    roi_files = list(project_path.rglob("*roi*.py")) + list(project_path.rglob("*investment*.py"))
    for roi_file in roi_files:
        try:
            with open(roi_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            if "calculate" in content.lower():
                patterns["roi_calculation_patterns"].append({
                    "file": str(roi_file.relative_to(project_path)),
                    "calculation_methods": content.lower().count("def calculate"),
                    "financial_indicators": [
                        indicator for indicator in ["npv", "irr", "roi", "payback"]
                        if indicator in content.lower()
                    ]
                })
        except:
            continue
    
    # åˆ†ææ•°æ®é‡‡é›†æ¨¡å¼
    collector_files = list(project_path.rglob("*collector*.py")) + list(project_path.rglob("*crawl*.py"))
    for collector_file in collector_files:
        try:
            with open(collector_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            patterns["data_collection_patterns"].append({
                "file": str(collector_file.relative_to(project_path)),
                "async_methods": content.count("async def"),
                "api_calls": content.lower().count("requests.") + content.lower().count("aiohttp"),
                "data_sources": [
                    source for source in ["ctrip", "meituan", "gaode", "baidu"]
                    if source in content.lower()
                ]
            })
        except:
            continue
    
    return patterns

def main():
    """ä¸»å‡½æ•°"""
    
    project_path = "/Users/jx/Downloads/é…’åº—åˆ†æå·¥å…·"
    
    print("ğŸ” å¼€å§‹æ·±åº¦ä»£ç åˆ†æ (æ¨¡æ‹ŸSerena MCPåŠŸèƒ½)")
    print("=" * 60)
    
    # é¡¹ç›®ç»“æ„åˆ†æ
    print("ğŸ“Š åˆ†æé¡¹ç›®ç»“æ„...")
    structure_analysis = analyze_project_structure(project_path)
    
    # ä¸šåŠ¡é€»è¾‘åˆ†æ
    print("ğŸ—ï¸ åˆ†æä¸šåŠ¡é€»è¾‘æ¨¡å¼...")
    business_analysis = analyze_business_logic_patterns(project_path)
    
    # ç»¼åˆæŠ¥å‘Š
    comprehensive_report = {
        "analysis_timestamp": "2025-07-29T23:40:00Z",
        "project_structure": structure_analysis,
        "business_patterns": business_analysis,
        "recommendations": {
            "immediate_actions": structure_analysis["improvement_suggestions"][:3],
            "architectural_improvements": structure_analysis["improvement_suggestions"][3:],
            "performance_optimizations": [
                "å¢åŠ å¼‚æ­¥å¤„ç†èƒ½åŠ›",
                "å®ç°æ•°æ®åº“è¿æ¥æ± ",
                "æ·»åŠ ç¼“å­˜å±‚"
            ]
        }
    }
    
    # æ‰“å°æŠ¥å‘Š
    print_analysis_report(comprehensive_report)
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    with open("manual_code_analysis_report.json", "w", encoding="utf-8") as f:
        json.dump(comprehensive_report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: manual_code_analysis_report.json")

def print_analysis_report(report: Dict):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    
    print("\n" + "="*60)
    print("ğŸ¨ é…’åº—åˆ†æå·¥å…· - æ·±åº¦ä»£ç åˆ†ææŠ¥å‘Š")
    print("="*60)
    
    # é¡¹ç›®æ¦‚è§ˆ
    overview = report["project_structure"]["project_overview"]
    print(f"\nğŸ“Š é¡¹ç›®æ¦‚è§ˆ:")
    print(f"   ğŸ“„ Pythonæ–‡ä»¶æ•°: {overview['total_python_files']}")
    print(f"   ğŸ“ ä»£ç æ€»è¡Œæ•°: {overview['total_lines_of_code']:,}")
    print(f"   ğŸ—ï¸ ç±»æ€»æ•°: {overview['total_classes']}")
    print(f"   âš™ï¸ å‡½æ•°æ€»æ•°: {overview['total_functions']}")
    
    # æ¶æ„æ¨¡å¼
    arch = report["project_structure"]["architecture_patterns"]
    print(f"\nğŸ—ï¸ æ¶æ„æ¨¡å¼åˆ†æ:")
    print(f"   ğŸ”§ æ ¸å¿ƒä¸šåŠ¡ç±»: {arch['core_business_classes']}")
    print(f"   ğŸ› ï¸ æœåŠ¡ç±»: {arch['service_classes']}")
    print(f"   ğŸ“ˆ åˆ†æå™¨ç±»: {arch['analyzer_classes']}")
    print(f"   ğŸ“Š æ¨¡å‹ç±»: {arch['model_classes']}")
    
    # ä»£ç è´¨é‡
    quality = report["project_structure"]["code_metrics"]
    print(f"\nğŸ“ˆ ä»£ç è´¨é‡è¯„ä¼°:")
    print(f"   ğŸ¯ å¯ç»´æŠ¤æ€§è¯„åˆ†: {quality['maintainability_score']:.1f}/10")
    print(f"   âš ï¸ å¤§å‹ç±»æ•°é‡: {quality['complexity_indicators']['large_classes']}")
    print(f"   âš ï¸ å¤æ‚å‡½æ•°æ•°é‡: {quality['complexity_indicators']['long_functions']}")
    
    # æ”¹è¿›å»ºè®®
    suggestions = report["project_structure"]["improvement_suggestions"]
    if suggestions:
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for i, suggestion in enumerate(suggestions[:5], 1):
            print(f"   {i}. {suggestion}")
    
    # ROIè®¡ç®—åˆ†æ
    roi_patterns = report["business_patterns"]["roi_calculation_patterns"]
    if roi_patterns:
        print(f"\nğŸ’° ROIè®¡ç®—æ¨¡å—åˆ†æ:")
        for pattern in roi_patterns[:2]:
            print(f"   ğŸ“ {pattern['file']}")
            print(f"      è®¡ç®—æ–¹æ³•æ•°: {pattern['calculation_methods']}")
            print(f"      è´¢åŠ¡æŒ‡æ ‡: {', '.join(pattern['financial_indicators'])}")

if __name__ == "__main__":
    main()